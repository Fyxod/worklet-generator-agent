[
    {
        "Title": "Real-time Video Call Anti-Aliasing using On-Device TFLite",
        "Problem Statement": "Develop and deploy a real-time video anti-aliasing solution for low-bandwidth video calls using an on-device TFLite model, improving visual clarity and reducing bandwidth consumption, catering to users with limited connectivity.",
        "Description": "Existing video conferencing solutions struggle with aliasing artifacts under poor network conditions. This project leverages the power of on-device machine learning to reduce aliasing in real-time, enhancing user experience without relying on high bandwidth. The provided document highlights existing work in this direction.",
        "Challenge / Use Case": "Poor video quality in low-bandwidth environments, impacting user experience and collaboration.",
        "Deliverables": "Android application with real-time anti-aliasing, fine-tuned TFLite model, performance evaluation report, and architecture diagram.",
        "KPIs": [
            "Peak Signal-to-Noise Ratio (PSNR)",
            "Structural Similarity Index (SSIM)",
            "Bandwidth reduction (%)",
            "Frames per second (FPS)"
        ],
        "Prerequisites": [
            "TensorFlow Lite",
            "Android Development",
            "Image Processing Fundamentals",
            "Video Compression Techniques",
            "Convolutional Neural Networks (CNNs)",
            "Python"
        ],
        "Infrastructure Requirements": "Android smartphone for testing, Google Colab for model training (GPU recommended, but not mandatory).",
        "Tentative Tech Stack": "Python, TensorFlow, TensorFlow Lite, Android Studio, OpenCV.",
        "Milestones (6 months)": {
            "M2": "Dataset creation/collection and initial model training.",
            "M4": "TFLite model optimization and integration into Android application.",
            "M6": "App testing, performance evaluation, and report generation."
        },
        "Reference Work": [
            {
                "Title": "LoRa-Powered Energy-Effcient Object Detection Mechanism in Edge Computing Nodes",
                "Link": "https://ieeexplore.ieee.org/abstract/document/9987393/",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Near-brain computation: embedding P300-based BCIs at EEG headset level",
                "Link": "https://ieeexplore.ieee.org/abstract/document/10164428/",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Recognizing human activities in a privacy-preserving way",
                "Link": "https://webthesis.biblio.polito.it/33113/",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": " DeepReality: An open source framework to develop AI-based augmented reality applications",
                "Link": "https://www.sciencedirect.com/science/article/pii/S0957417424003956",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "MicroAI: embedded artificial intelligence for human activity recognition on smart glasses",
                "Link": "https://theses.hal.science/tel-04049008/",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Reinforcement learning on resource bounded systems",
                "Link": "https://era.library.ualberta.ca/items/cbbd0fa7-48f8-4118-babd-d5833c7d9ee4",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": " Mechanical Design and Control System Development of Novel 2 Degree-of-freedom Ankle and Balance Rehabilitation Robotic System",
                "Link": "https://repository.library.northeastern.edu/files/neu:rx914r47t/fulltext.pdf",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Dise\u00f1o e implementaci\u00f3n de un Holter de ECG para la detecci\u00f3n de arritmias ventriculares con inteligencia artificial",
                "Link": "https://upcommons.upc.edu/handle/2117/382885",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "[CITATION][C] Vision Based Traffic Panel Text Information and Sign Retrieval",
                "Link": null,
                "Description": "",
                "Tag": "scholar"
            }
        ]
    },
    {
        "Title": "Generative AI for Personalized Video Call Backgrounds",
        "Problem Statement": "Develop a generative AI model to create personalized and dynamic video call backgrounds based on user preferences or real-time environment analysis, enhancing privacy and user engagement during video conferencing.",
        "Description": "Standard virtual backgrounds are often static and lack personalization. This project aims to generate dynamic backgrounds leveraging generative AI techniques. It can provide personalized backgrounds based on the caller\u2019s mood, activity, or even current location data.",
        "Challenge / Use Case": "Improving user privacy and engagement during video calls with dynamic, personalized backgrounds.",
        "Deliverables": "Android application with generative background functionality, trained generative model (GAN, Diffusion Model), performance evaluation report.",
        "KPIs": [
            "User perceived quality (visual survey)",
            "Inference time (ms)",
            "Diversity of generated backgrounds",
            "Model size (MB)"
        ],
        "Prerequisites": [
            "Generative Adversarial Networks (GANs)",
            "Diffusion Models",
            "Deep Learning Frameworks (PyTorch/TensorFlow)",
            "Image Processing",
            "Android Development",
            "Python"
        ],
        "Infrastructure Requirements": "Google Colab with GPU for model training. Android smartphone for testing.",
        "Tentative Tech Stack": "Python, PyTorch/TensorFlow, OpenCV, Android Studio.",
        "Milestones (6 months)": {
            "M2": "Data collection and initial GAN/Diffusion model training.",
            "M4": "Model optimization and integration into Android app.",
            "M6": "App testing, user evaluation, and final report."
        },
        "Reference Work": [
            {
                "Title": " Where is the Boundary? Understanding How People Recognize and Evaluate Generative AI-extended Videos",
                "Link": "https://faculty.washington.edu/weicaics/paper/papers/KeWLAC2025.pdf",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Making AI-Enhanced Videos: Analyzing Generative AI Use Cases in YouTube Content Creation",
                "Link": "https://arxiv.org/abs/2503.03134",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Ai video editor: A conceptual review in generative arts",
                "Link": "https://books.google.com/books?hl=en&lr=&id=MWPjEAAAQBAJ&oi=fnd&pg=PA16&dq=Generative+AI+video+backgrounds&ots=umMh1CqAqW&sig=0W9vnpGNIYADLv_tk4kTXX_BnRM",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Video generative adversarial networks: a review",
                "Link": "https://dl.acm.org/doi/abs/10.1145/3487891",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Enhancing Pedagogy with Generative AI: Video Production from Course Descriptions",
                "Link": "https://dl.acm.org/doi/abs/10.1145/3674912.3674922",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": " A review of generative AI from historical perspectives",
                "Link": "https://www.researchgate.net/profile/Kishor-Datta-Gupta/publication/368543465_A_Review_of_Generative_AI_from_Historical_Perspectives/links/63edde7f19130a1a4a82a316/A-Review-of-Generative-AI-from-Historical-Perspectives.pdf",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "BlendScape: Enabling End-User Customization of Video-Conferencing Environments through Generative AI",
                "Link": "https://dl.acm.org/doi/abs/10.1145/3654777.3676326",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Actanywhere: Subject-aware video background generation",
                "Link": "https://proceedings.neurips.cc/paper_files/paper/2024/hash/34a9582cd36c0b6eb94e5cf11bd6a008-Abstract-Conference.html",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "SimTube: Simulating Audience Feedback on Videos using Generative AI and User Personas",
                "Link": "https://dl.acm.org/doi/abs/10.1145/3708359.3712146",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Exploring the Application of Generative AI by YouTube Content Creators",
                "Link": "https://portal.sinteza.singidunum.ac.rs/paper/953",
                "Description": "",
                "Tag": "scholar"
            }
        ]
    },
    {
        "Title": "Voice-Controlled Video Call Enhancement with Noise Suppression & Clarity",
        "Problem Statement": "Implement a voice-controlled system within a video call application to dynamically adjust audio settings (noise suppression, echo cancellation, clarity boosting) based on user voice commands, improving call quality.",
        "Description": "Current video conferencing often lacks adaptive audio enhancements. This project explores using voice commands to control audio processing in real-time, offering a hands-free experience and better call clarity. It leverages speech recognition and signal processing techniques.",
        "Challenge / Use Case": "Improving audio quality and user control during video calls in noisy environments.",
        "Deliverables": "Android application with voice-controlled audio enhancement, trained speech recognition model, performance evaluation report.",
        "KPIs": [
            "Speech recognition accuracy (%)",
            "Noise reduction level (dB)",
            "User satisfaction score",
            "Latency of voice command processing (ms)"
        ],
        "Prerequisites": [
            "Speech Recognition (e.g., Google Speech-to-Text)",
            "Audio Signal Processing",
            "Android Development",
            "Python",
            "Machine Learning Fundamentals",
            "Real-time Audio Processing"
        ],
        "Infrastructure Requirements": "Android smartphone for testing, Google Colab for training (optional).",
        "Tentative Tech Stack": "Python, TensorFlow/PyTorch, Android Studio, Audio Processing Libraries.",
        "Milestones (6 months)": {
            "M2": "Speech recognition model training and integration.",
            "M4": "Audio processing algorithms implementation and integration.",
            "M6": "App testing, user evaluation, and report generation."
        },
        "Reference Work": [
            {
                "Title": "Audio-visual enhancement of speech in noise",
                "Link": "https://pubs.aip.org/asa/jasa/article-abstract/109/6/3007/547791",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "VC-ENHANCE: Speech Restoration with Integrated Noise Suppression and Voice Conversion",
                "Link": "https://arxiv.org/abs/2409.06126",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Sensing to hear: Speech enhancement for mobile devices using acoustic signals",
                "Link": "https://dl.acm.org/doi/abs/10.1145/3478093",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "A review on voice over internet protocol on conference call with mobile phone",
                "Link": "https://journals.sagepub.com/doi/abs/10.3233/KES-200035",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Using Artificial Intelligence to Filter out Barking, Typing, and other Noise from Video Calls in Microsoft Teams",
                "Link": "https://ijcionline.com/abstract/12123ijci03",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "When evil calls: Targeted adversarial voice over ip network",
                "Link": "https://dl.acm.org/doi/abs/10.1145/3548606.3560671",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Icassp 2023 deep noise suppression challenge",
                "Link": "https://ieeexplore.ieee.org/abstract/document/10474162/",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Real-Time Suppression of Non-stationary Noise for Web-Based Calling Applications",
                "Link": "https://link.springer.com/chapter/10.1007/978-981-99-5652-4_14",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "A comparative study of noise reduction techniques for automatic speech recognition systems",
                "Link": "https://ieeexplore.ieee.org/abstract/document/7732361/",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "ICA based Noise Reduction in Mobile Phone Speech Communications",
                "Link": "https://ieeexplore.ieee.org/abstract/document/10660984/",
                "Description": "",
                "Tag": "scholar"
            }
        ]
    },
    {
        "Title": "Smart Zoom & Framing with On-Device Object Detection",
        "Problem Statement": "Develop an intelligent framing system for video calls that automatically detects faces and objects within the camera view and dynamically adjusts the zoom and framing to keep participants and important content centered.",
        "Description": "Current video calls often require manual adjustments to ensure all participants are visible. This project uses on-device object detection to automatically identify and frame individuals and relevant objects within the camera's field of view.",
        "Challenge / Use Case": "Improving the viewing experience in video calls by automatically adjusting the camera framing.",
        "Deliverables": "Android application with intelligent framing functionality, trained object detection model, performance evaluation report.",
        "KPIs": [
            "Object detection accuracy (%)",
            "Framing stability (degrees of movement)",
            "Processing time (ms)",
            "User satisfaction"
        ],
        "Prerequisites": [
            "Object Detection (e.g., YOLO, SSD)",
            "Computer Vision",
            "Android Development",
            "Python",
            "Machine Learning Fundamentals"
        ],
        "Infrastructure Requirements": "Android smartphone for testing, Google Colab for training (GPU recommended).",
        "Tentative Tech Stack": "Python, TensorFlow/PyTorch, OpenCV, Android Studio.",
        "Milestones (6 months)": {
            "M2": "Object detection model training and optimization.",
            "M4": "Integration with the Android camera API.",
            "M6": "App testing, performance evaluation, and report generation."
        },
        "Reference Work": [
            {
                "Title": "Edge-assisted online on-device object detection for real-time video analytics",
                "Link": "https://ieeexplore.ieee.org/abstract/document/9488741/",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Optimized convolutional neural network architectures for efficient on-device vision-based object detection",
                "Link": "https://link.springer.com/article/10.1007/s00521-021-06830-w",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": " On-device object detection for more efficient and privacy-compliant visual perception in context-aware systems",
                "Link": "https://www.mdpi.com/2076-3417/11/19/9173",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": " Domain-Specific On-Device Object Detection Method",
                "Link": "https://www.mdpi.com/1099-4300/24/1/77",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Ultra-efficient on-device object detection on ai-integrated smart glasses with tinyissimoyolo",
                "Link": "https://arxiv.org/abs/2311.01057",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Mnasfpn: Learning latency-aware pyramid architecture for object detection on mobile devices",
                "Link": "http://openaccess.thecvf.com/content_CVPR_2020/html/Chen_MnasFPN_Learning_Latency-Aware_Pyramid_Architecture_for_Object_Detection_on_Mobile_CVPR_2020_paper.html",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Continuous, real-time object detection on mobile devices without offloading",
                "Link": "https://ieeexplore.ieee.org/abstract/document/9355581/",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Bed: A real-time object detection system for edge devices",
                "Link": "https://dl.acm.org/doi/abs/10.1145/3511808.3557168",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "FlexPatch: Fast and accurate object detection for on-device high-resolution live video analytics",
                "Link": "https://ieeexplore.ieee.org/abstract/document/9796984/",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Edge assisted real-time object detection for mobile augmented reality",
                "Link": "https://dl.acm.org/doi/abs/10.1145/3300061.3300116",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "coral-streaming-object-detector",
                "Description": "This example will help you deploy a streaming camera feed with realtime people detection using the Coral Edge TPU for on-device ML inferencing.",
                "Link": "https://github.com/balena-io-examples/coral-streaming-object-detector",
                "Tag": "github"
            }
        ]
    },
    {
        "Title": "AI-Powered Background Blur based on Depth Estimation",
        "Problem Statement": "Develop an algorithm to create a realistic background blur effect during video calls using depth estimation from the camera, enhancing privacy and focusing attention on the participant.",
        "Description": "Traditional background blur uses chroma keying, which can be inaccurate and requires specific lighting conditions. This project aims to use depth estimation to create a more natural and accurate background blur effect without relying on green screens.",
        "Challenge / Use Case": "Creating a natural and accurate background blur effect for video calls without a green screen.",
        "Deliverables": "Android application with depth-based background blur, trained depth estimation model, performance evaluation report.",
        "KPIs": [
            "Depth estimation accuracy (RMSE)",
            "Blur quality (visual assessment)",
            "Processing time (ms)",
            "User satisfaction"
        ],
        "Prerequisites": [
            "Depth Estimation",
            "Computer Vision",
            "Android Development",
            "Python",
            "Machine Learning Fundamentals"
        ],
        "Infrastructure Requirements": "Android smartphone with depth sensor (if available), Google Colab for training (GPU recommended).",
        "Tentative Tech Stack": "Python, TensorFlow/PyTorch, OpenCV, Android Studio.",
        "Milestones (6 months)": {
            "M2": "Depth estimation model training and optimization.",
            "M4": "Integration with the Android camera API and background blur effect.",
            "M6": "App testing, performance evaluation, and report generation."
        },
        "Reference Work": [
            {
                "Title": "Joint depth estimation and camera shake removal from single blurry image",
                "Link": "https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Hu_Joint_Depth_Estimation_2014_CVPR_paper.html",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": " Depth Estimation and Blur Removal from a Single Out-of-focus Image.",
                "Link": "https://porikli.com/mysite/pdfs/porikli%202017%20-%20Depth%20estimation%20and%20blur%20removal%20from%20a%20single%20out-of-focus%20image.pdf",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Automatic Depth Estimation and Background Blurring of Animated Scenes Based on Deep Learning.",
                "Link": "https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=07650019&AN=173376360&h=vw6%2FbsE5WpQK7My9Fhl0%2B4TZsolRwyQkjkRJbtcDEtsEr4rshTMWL5SKXQqpbZ47vEZb6pAMz610%2F0MAPneeIw%3D%3D&crl=c",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Deep depth from defocus: how can defocus blur improve 3D estimation using dense neural networks?",
                "Link": "https://openaccess.thecvf.com/content_eccv_2018_workshops/w3/html/Carvalho_Deep_Depth_from_Defocus_how_can_defocus_blur_improve_3D_ECCVW_2018_paper.html",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Depth from motion and optical blur with an unscented Kalman filter",
                "Link": "https://ieeexplore.ieee.org/abstract/document/6104389/",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Realistic depth blur for images with range data",
                "Link": "https://link.springer.com/chapter/10.1007/978-3-642-03778-8_7",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "DEPTH MAP GENERATION USING DEFOCUS BLUR ESTIMATOR AND ITS CONFIDENCE",
                "Link": "https://s-space.snu.ac.kr/handle/10371/119155",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Blur calibration for depth from defocus",
                "Link": "https://ieeexplore.ieee.org/abstract/document/7801533/",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": " Blur and the perception of depth at occlusions",
                "Link": "https://iovs.arvojournals.org/article.aspx?articleid=2517510",
                "Description": "",
                "Tag": "scholar"
            },
            {
                "Title": "Single image deblurring and camera motion estimation with depth map",
                "Link": "https://ieeexplore.ieee.org/abstract/document/8658686/",
                "Description": "",
                "Tag": "scholar"
            }
        ]
    }
]