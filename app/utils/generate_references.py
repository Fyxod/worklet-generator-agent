import requests
from langchain.prompts import ChatPromptTemplate
import xml.etree.ElementTree as ET
from app.llm import invoke_llm
from langchain.schema.messages import HumanMessage
from app.utils.reference_functions.github import get_github_references
from app.utils.reference_functions.google_scholar import get_google_scholar_references
from app.utils.search_functions.search import search_references
from concurrent.futures import ThreadPoolExecutor
from app.utils.prompt_templates import arcive_temp
from time import sleep
import json
from app.utils.discord import  notify_discord_on_error

def getReferenceWork(title, model = "gemma3:27b"):
    """
        Generates a list of references related to the given title by fetching data 
        from multiple sources such as GitHub, Google Scholar, and a general search.
        Args:
            title (str): The title or topic for which references are to be generated.
            model (str, optional): The model used for generating keywords. Defaults to "gemma3:27b".
        Returns:
            list: A combined list of references from Google Scholar, GitHub, and other sources.
        Raises:
            Exception: If an error occurs while generating the keyword, it is logged, 
                       and the title is used as the fallback keyword.
        Notes:
            - Uses a ThreadPoolExecutor to fetch references concurrently from GitHub 
              and Google Scholar.
            - If no references are found from Google Scholar, retries after a delay 
              and falls back to a general search if necessary.
            - Errors during keyword generation are notified via Discord.
    """
    
    keyword = ""
    try:
        keyword = getKeyword(title, model)
    except Exception as e:
        notify_discord_on_error(message="error in geting keyword",error=e)
        keyword = title

    with ThreadPoolExecutor() as executor:
        future_github = executor.submit(get_github_references, keyword)
        future_scholar = executor.submit(get_google_scholar_references, keyword)
        githubReferences = future_github.result()
        googleScholarReferences = future_scholar.result()
        googleReferences = []

        if len(googleScholarReferences) == 0:
            sleep(5)
            googleScholarReferences = get_google_scholar_references(keyword)

        if len(googleScholarReferences) == 0:
            googleReferences = search_references(keyword, max_results=10)
    response = []
    response.extend(googleScholarReferences)
    response.extend(githubReferences)
    response.extend(googleReferences)
    return response



def getKeyword(title, model):
    """
    Generates a keyword or response based on the given title using a specified language model.
    Args:
        title (str): The title or input text to generate a keyword or response for.
        model (Any): The language model to be used for generating the response.
    Returns:
        Any: The response generated by the language model based on the provided title.
    """
    
    prompt = arcive_temp().format(title=title)
    response = invoke_llm(prompt, model)
    return response
