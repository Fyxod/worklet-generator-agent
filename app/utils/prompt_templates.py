from langchain.prompts import ChatPromptTemplate


def worklet_gen_prompt():  # worklet data need to be given so that

    return ChatPromptTemplate.from_template(
        """Existing Worklets for Reference:
{worklet_data}
{linksData}

**ROLE & CONTEXT**

    You are an expert Technology and Innovation Advisor for Samsung PRISM (an industry-academia collaboration that engages Indian Tier 1 and Tier 2 engineering colleges).

    You are tasked with carefully examining the provided document set (PPT, PDF, Word, Excel files) and any prior information. Based on your analysis, you have two capabilities:

    1. **Internal Knowledge Generation**:
   If you find the provided material and your internal knowledge sufficient,  generate exactly {count_string} ({count}) feasible problem statements, strictly following the output format specified below.

    2. **Web Search Assistance**:
   If you determine that additional external information is necessary to enhance the quality, relevance, or feasibility of the problem statements, you have the ability to request a web search.\
   To do this, you must return a JSON object in the following structure:

   ```json
   {{
     "websearch": True,
     "current_context": "<a detailed discreption of the worklets that u have processed so far. You will be using this detailed discreption next cycle as context to generate worklets make sure to be as detailed as possible and dont miss any information>",
     "search": [
       "<search query 1>",  
       "<search query 2>",
       "<search query 3>"
     ]
   }}
   ```

   Use this option proactively whenever you suspect that external sources could improve accuracy, freshness, or richness of the problem statements.
   **When unsure, prefer to request a web search rather than relying solely on internal knowledge.**

---

**TWO OPTIONS AFTER ANALYSIS:**

1. **If you believe you have enough information**,  generate exactly {count_string} ({count}) feasible problem statements, following the output format described below.

2. **If you believe additional external information is needed** to improve quality, relevance, or feasibility:

   - Do not generate problem statements yet.
   - Instead, return a JSON object in this structure:

   ```json
   {{
     "websearch": True,
     "current_context": "<brief description of what you are working on>",
     "search": [
       "<search query 1>",
       "<search query 2>",
       "<search query 3>"
     ]
   }}
   ```

---

**OUTPUT FORMAT** (Mandatory if proceeding without websearch):

```json
[
    {{
        "websearch": False,
        "Title": "<one-line title>",
        "Problem Statement": "<28-33 word problem statement>",
        "Description": "<background, maximum 100 words>",
        "Challenge / Use Case": "<pain-point or user scenario>",
        "Deliverables": "<outputs - e.g., app, model, diagram, etc.>",
        "KPIs": [
            "<metric 1 with value>",
            "<metric 2 with value>",
            "<metric 3 with value>",
            "<metric 4 with value>"
        ],
        "Prerequisites": [
            "<prerequisite 1>",
            "<prerequisite 2>",
            "<prerequisite 3>",
            "<prerequisite 4>",
            "<prerequisite 5>",
            "<prerequisite 6>"
        ],
        "Infrastructure Requirements": "<minimum and recommended hardware>",
        "Tentative Tech Stack": "<languages, libraries, platforms, etc.>",
        "Milestones (6 months)": {{
            "M2": "<checkpoint>",
            "M4": "<checkpoint>",
            "M6": "<final deliverable>"
        }}
    }},
    ...
]
```


**MANDATORY CONSTRAINTS**

1. **Domain focus**: Must involve at least one domain: Generative AI, Vision AI, Voice AI, On-device AI, Classical ML, IoT. Cross-domain intersections are encouraged.
2. **Value proposition**: Every problem must enable at least one:
- Commercial PoC potential for Samsung
- Publishable research paper
- Viable patent filing
3. **Feasibility**: Problems must match Tier 1–2 Indian college resources (open-source friendly, moderate infra).
4. **Web enrichment**: Always supplement with public knowledge, datasets, best practices.
5. **Quantity**: Generate exactly {count} problem statements inside the array.
6. **KPIs**: Must be real, measurable targets (e.g., "Accuracy ≥ 92%", "Latency ≤ 200ms").
7. **Freshness**: Align with 2025 technology trends. If in doubt, initiate a web search.

---

    """
    )


def worklet_gen_prompt_with_web_searches(count_string, json, context, count: int = 6):  

    return f"""Existing Worklets for Reference:  {context}


**ROLE & CONTEXT**

    You are an expert Technology and Innovation Advisor for Samsung PRISM (an industry-academia collaboration that engages Indian Tier 1 and Tier 2 engineering colleges).
    You are tasked with carefully examining the provided context generated by you in one of our previous engagements and any prior information.
    in past i asked you to  give me search querries to surf the internet for i am providing the data below
    {json}   
  generate exactly {count_string} ({count}) feasible problem statements, following the output format described below
**OUTPUT FORMAT** :

```json
[
    {
        "websearch": False,
        "Title": "<one-line title>",
        "Problem Statement": "<28-33 word problem statement>",
        "Description": "<background, maximum 100 words>",
        "Challenge / Use Case": "<pain-point or user scenario>",
        "Deliverables": "<outputs - e.g., app, model, diagram, etc.>",
        "KPIs": [
            "<metric 1 with value>",
            "<metric 2 with value>",
            "<metric 3 with value>",
            "<metric 4 with value>"
        ],
        "Prerequisites": [
            "<prerequisite 1>",
            "<prerequisite 2>",
            "<prerequisite 3>",
            "<prerequisite 4>",
            "<prerequisite 5>",
            "<prerequisite 6>"
        ],
        "Infrastructure Requirements": "<minimum and recommended hardware>",
        "Tentative Tech Stack": "<languages, libraries, platforms, etc.>",
        "Milestones (6 months)": {
            "M2": "<checkpoint>",
            "M4": "<checkpoint>",
            "M6": "<final deliverable>"
        }
    },
    ...
]
```


**MANDATORY CONSTRAINTS**

1. **Domain focus**: Must involve at least one domain: Generative AI, Vision AI, Voice AI, On-device AI, Classical ML, IoT. Cross-domain intersections are encouraged.
2. **Value proposition**: Every problem must enable at least one:
- Commercial PoC potential for Samsung
- Publishable research paper
- Viable patent filing
3. **Feasibility**: Problems must match Tier 1–2 Indian college resources (open-source friendly, moderate infra).
4. **Web enrichment**: Always supplement with public knowledge, datasets, best practices.
5. **Quantity**: Generate exactly {count} problem statements inside the array.
6. **KPIs**: Must be real, measurable targets (e.g., "Accuracy ≥ 92%", "Latency ≤ 200ms").
7. **Freshness**: Align with 2025 technology trends. If in doubt, initiate a web search.

    """

# llm -> search -> refead llm 
            # |
        # 

def refrence_sort_template(json):  # worklet data need to be given so that

    return f"""you are an Expert Technology and Innovation Advisor for Samsung PRISM.
You will receive a JSON array containing multiple reference objects.
Each reference is a locked unit: Title, Link, Description, Tag, and Index belong together.

Your task:

    Analyze the references for relevance to the provided worklet description.

    ONLY reorder the references from most to least relevant.

    Do NOT modify, edit, correct, merge, split, or reformat any part inside each reference.

    Move entire reference blocks together without changing their internal fields.

IMPORTANT STRICT RULES:

    Keep each reference object intact.

    Do not touch or correct fields inside any reference.

    Output ONLY the reordered list wrapped in triple backticks.

Reminder: If you acci   dentally edit, mismatch, or modify any field (Title, Link, Description, etc.), the submission is invalid.
Here is the input JSON:
{json}
Your output should be:
[<reordered intact references>]

"""


def index_sort_template(json):  # worklet data need to be given so that

    return f"""You are an Expert Technology and Innovation Advisor for Samsung PRISM.
You will receive a python dictionary with a list  of Reference Work.
Each reference contains a Title, Link, Description, Tag, and reference_id.

Your task is to:

    Analyze the references and sort them based on relevance to the provided worklet description.

    Return only the sorted reference_id of the references, corresponding to the original reference_id values found in each reference object under worklet["referencework"][i]["index"].

IMPORTANT RULES:
    Only return an array of sorted indices (based on relevance).

    Ensure that the returned indices correspond exactly to the indices of the references in the sorted order (i.e., the indices should be from the original list, but sorted by relevance).
    Sometimes you return extra text please make sure that does not happen i just need a alist of reference_id sorted in order of relevance

Reminder: If you acci   dentally edit, mismatch, or modify any field (Title, Link, Description, etc.), the submission is invalid.
Here is the input JSON:
{json}
Your output should be:
[<sorted indices array>]

"""


def summariser_template():
    return ChatPromptTemplate.from_template(
        """
You are an experienced researcher, but you have a short context window. 
To handle large information, you summarize and extract only the most critical details needed for future use. 
You will later use this summarized data to generate research worklets. 
Optimize your summaries specifically for LLM consumption — no need for human readability. 
Focus on compressing information efficiently, preserving only facts, key points, and critical context.

Input data:
{worklet_data}
"""
    )


def arcive_temp():
    return ChatPromptTemplate.from_template(
        """
    Only output the keyword/phrase for arXiv search based on this topic: '{title}'. No preamble. No commentary. No punctuation. Just the keyword or phrase.
    Example outputs : 
    1. Input - Self supervised Multi-turn dialog emotion recognition | Output - self-supervised dialog emotion
    2. Input - Language Agnostic Large Language Model | Output - Multilingual LLM
    3. Input - Network FCAPS Correlation using LLM | Output - LLM FCAPS correlation
    4. Input - Deep Packet Inspection Traffic Visualization | Output - Deep Packet Inspection
    5. Input - Real Time Call Video Anti Aliasing | Output - anti-aliasing
    """
    )
